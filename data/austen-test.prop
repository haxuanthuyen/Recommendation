#location of the training file
trainFile = data/dientucongnghe/train.dientucongnghe
#location where you would like to save (serialize to) your
#classifier; adding .gz at the end automatically gzips the file,
#making it faster and smaller
serializeTo = data/dientucongnghe/model.dientucongnghe.gz
testFile=data/dientucongnghe/test.dientucongnghe

#structure of your training file; this tells the classifier
#that the word is in column 0 and the correct answer is in
#column 1
#map = word=0,tag=1,answer=2
map = word=0,answer=1

#distSimLexicon = egw4-reut.512.clusters
#useDistSim = true

#these are the features we'd like to train with
#some are discussed below, the rest can be
#understood by looking at NERFeatureFactory
useClassFeature=true
useWord=true
#useWordPairs=true
useNGrams=true
#no ngrams will be included that do not contain either the
#beginning or end of the word
noMidNGrams=true
useDisjunctive=true
maxNGramLeng=6
usePrev=true
useNext=true
use2W=true
useLC=true
useWordPairs=true
useSymWordPairs=true
useSequences=true
usePrevSequences=true
maxLeft=1
#the next 4 deal with word shape features
useTypeSeqs=true
useTypeSeqs2=true
useTypeySequences=true
#wordShape=chris2useLC
useOccurrencePatterns=true
useLongSequences=true
useLastRealWord=true
useNextRealWord=true
normalize=true
disjunctionWidth=5
#useObservedSequencesOnly=true
QNsize=25
featureDiffThresh=0.05
readerAndWriter=edu.stanford.nlp.sequences.ColumnDocumentReaderAndWriter

#usePrevNumberPattern=true
#useNextNumberPattern=true
#prevWords=data/pn.prev.txt
#nextWords=data/pn.next.txt
#useLowerCase=true
#useTags=true
#cleanGazette=true
#gazette=austen.gaz.txt
